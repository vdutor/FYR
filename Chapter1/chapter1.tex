\chapter{Introduction}  %Title of the First Chapter

Using past experience to update ones behaviour is what differentiates intelligent beings from other creatures in our world. To artificially create said systems, that can learn from data acquired through experience, is the crowning goal of the field of Artificial Intelligence (AI) and Machine Learning (ML) \citep{turing}.
%In Machine Learning, which is a subdomain of AI, this is done through the manipulation of mathematical formalisms that can be translated into computer algorithms. 
Realising this goal will have a large impact on the world and society we live in, as it will liberate humans from tasks that require cognition, like driving cars, booking appointments, and interpreting and acting on medical records, to give a few examples. Though, arguably, the field has still a long way to go before fulfilling its full potential \citep{grace2018will}.

An elegant approach to formalise the concept of learning through acquired experience is that of \emph{Bayesian learning} \citep{murphy}. In this framework, one specifies beliefs about quantities of interest, and updates them after observing data. The beliefs are represented using probability distributions: the \emph{prior} describes what is known about the quantity before any data is observed, and the so-called \emph{likelihood} describes the relation between the observed data and the quantity of interest. The framework provides a recipe for obtaining an updated belief over the quantity of interest after data has been observed. This distribution is known as the \emph{posterior}. Bayesian learning makes decisions atop these beliefs, and uses the posterior to reason about the optimality of a decision or the cost associated to a certain action.

The performance of a decision-making system will depend on the speed at which it can learn and the optimality of the decisions made---quantified by the \emph{regret}. It can be shown that, under certain assumptions, Bayesian learning gives rise to the optimal regret \citep{Lattimore}. However, such excellence comes at a high computational cost, which in many scenarios renders Bayesian learning---in its purest form---impractical. Fortunately, the literature has proposed many approximate methods which have lightened the computational complexity of the Bayesian paradigm \citep{Neal1993Probabilistic,jordan1999introduction,minka2001expectation}.

Unquestionably, models for decision-making systems need to deal with \emph{uncertainty}. They need to be able to quantify what is known, and what is not known. The importance of quantifying uncertainty for decision-making systems becomes clear from the many sources it can stem from. For example, there can be multiple different settings of a model that explain the data, so one needs to be uncertain about the setting that actually generated it. One also needs to be uncertain about the model itself, as most probably the model at hand is a simplification of the real-world process. Moreover, the environment in which the system operates may also be inherently uncertain, in which case even an infinite amount of data (i.e. experience) would not make the system any smarter (e.g., trying to predict the outcome of rolling a fair dice).

Gaussian Processes (GPs) \citep{rasmussen2006} can be argued to provide the perfect compromise between computational complexity and Bayesian rigour. Their non-parametric nature makes them complex enough to model a wide range of problems, while their kernel formulation makes them applicable to many different domains: graphs, vectors, images, etc. Instead of representing probability distributions on weights, Gaussian processes can be used to represent uncertainty directly on the function that the weights represents. The \emph{function-space} view of Gaussian processes makes them more amenable to mathematical analysis, which in turn leads to strong guarantees on the future performance of the system and overall robustness. This may be necessary for deploying these systems in critical applications. For these reasons studying Gaussian processes is very worthwhile.

This reports presents two pieces of research in the domain of approximate Bayesian inference for GP models conducted during the first year of my PhD degree. Namely, \cref{chapter:vish} introduces an interdomain inducing variable approach that speeds up inference and prediction in GPs by two orders of magnitude by making use of the spectral properties of the kernel. In \cref{chapter:dnn-as-point-estimate-for-dgps} we marry the strengths of deep neural networks and deep GPs by establishing an equivalence between the forward passes of both models. This results in models that can either be seen as neural networks with improved uncertainty prediction or deep GPs with increased prediction accuracy. The final part of this report, \cref{chapter:future-research}, elaborates on a future research agenda. Prior to all of this, we start with covering the theoretical background in \cref{chapter:theoretical-framework}.

The material presented in \cref{chapter:vish,chapter:dnn-as-point-estimate-for-dgps} is either published or is currently under review:
\begin{enumerate}
    \item \fullcite{Dutordoir2020spherical}
    \item \fullcite{dutordoir2021deep}
    \item \fullcite{dutordoir2021gpflux}
\end{enumerate}
