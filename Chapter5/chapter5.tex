\chapter{Future Research: Non-Parametric Decision Making in Non-Euclidian Spaces}
\label{chapter:future-research}

\section{Introduction}
To date, my research has focussed on using Gaussian processes (GPs) as building blocks for deep models, similar to neural network layers. In this vein, I have worked on (1) deep convolutional Gaussian processes that mimic the convolutional and layered architectures encountered in many contempory deep learning models \citep{Dutordoir2020convolutional}, (2) conditional density estimation models which are similar to Variational Auto Encoders \citep{dutordoir2018cde,Salimbeni2019}, and (3) more recently, deep Gaussian processes that have basis functions that are similar to neural network activation functions \citep{dutordoir2021deep} (discussed at length in \cref{chapter:dnn-as-point-estimate-for-dgps}). I have packaged these advances in a software toolbox, called GPflux \citep{dutordoir2021gpflux}, which provides these GP layers through a neural network like interface. The main advantage of this approach is that straightforward application of Bayesian principles leads to sensible results, which is not necissarily the case for normal neural networks [TODO CITE Wenzel]. The current state of research into using Gaussian processes as layers is that classification performance starting to be on-par with deep learning on simple datasets \citep{dutordoir2018cde}, but with good uncertainty quantification and automatic selection of hyperparameters working `out of the box'.

The primary focus of my previous research can be considered as `curve-fitting', i.e. finding the best function approximator when given examples of inputs and corresonponding outputs. In this setting we can consider two regimes: (1) the function is very complex but there is an abundance of high-quality and cheap data to learn the mapping, and (2) the function is of a simpler nature but the underlying data is limited, noisy and/or very expensive to acquire. As evidenced by many recent advances in domains such as natural language and vision, where indeed there is a large availablility of high-quality data, the first regime is a setting where deep learning thrives. The natural inductive bias of deep neural networks (DNNs) in combination with the low computational cost of training them on massive datasets has proven to be very effective. Arguably, performing (approximate) Bayesian inference in this regime will contribute little to the end result, and the computational cost associated with it makes it very cumbersome. 

The second regime, in which data is noisy, requires a completely different modelling paradigm. On the one hand, the noisy data forces the model to be uncertain about the signal that can be extracted from the given examples. On the other hand, the simpler nature of the function allows an expert to encode prior information about the problem at hand. This enables faster generalisation from little data, which can be necessary given the high cost of acquiring more. This is a setting where probabilistic Bayesian models thrive.

However, to fully valorise Bayesian models one needs to consider them as part of a larger `decision-making' system. In these systems probabilistic models can be used to determine optimal actions to take in order to achieve a certain outcome. % For example, finding the input value that minimises an unknown `black-box' function. % Since good decisions depend on the confidence of our knowledge, faithfully representing uncertainty is a crucial aspect of the models.

In the next chapter of my PhD, I want to develop such decision-making systems that use probabilistic models to drive their decisions. In particular, I want to focus on probabilistic models that take into account the geometry of the problem at hand. This will enable encorportating more accurately physical properties and constraints phyical properties of the system . In the next section we briefly discuss a MDP, a formal mathematical framework to decision making, and how we can define probabilistic models in non-Euclidian spaces. on  . We finish with suggesting concrete research topics and a real-world application.

% . I would like to focus on both the modelling side and the decision-making aspect using the model's outputs. In the next two sections we discuss the type of decision system we consider and how we can define Gaussian processes on these spaces. 

\section{Markov Decision Process}

A discrete-time Markov decision Process (MDP) is a stochastic control process. It provides a mathematical framework for decision making in situations where outcomes are partly random and partly under the control of a decision maker [CITE TODO]. A MDP is characterised by a 4-tuple, consiting of
\begin{enumerate}
    \item A state space $\mathcal{S}$,
    \item An action space $\mathcal{A}$,
    \item Reward density $p(r \given a, s)$: the immediate reward obtained after executing an action $a$ in a given state $s$,
    \item Transition density $p(s' \given a, s)$: transitioning from state $s$ to state $s'$, due to action $a$.
\end{enumerate}
It should be noted that this is a very broad definition, yet there are still many variations to it. For instance, one can consider deterministic reward and transition functions, continuous-time and partially observed MDPs. Many of these settings have been widely studied in the literature. 

The objective of an MDP is to find a `good' (probabilistic) policy function $\pi:\mathcal{S} \rightarrow \mathcal{X}$. This is a mapping that specifies which action a decision maker should take in a given state $s$. The goal is to find a sequence of actions that maximses the cumulative reward a decision maker obtains by obeying the policy $\pi$
\begin{equation}
    V^{(\pi)}(s_0) = \ExpSymb \sum_t r_t
\end{equation}
where XX

Optimal control vs. Reinformcement learning

There are many different ways to construct XXX

Model-based 

\paragraph{Bayesian optimisation}

Bayesian optimization [CITE] is a class of sequential search algorithms for finding a global minimizer
\begin{equation}
    x_* = \argmin_{x \in \mathcal{X}} f(x)
\end{equation}
of an unknown objective function $f$ defined over a domain of interest $X$. The function $f$ is not observed directly: instead, at each step the algorithm must select a query point $x \in X$ at which to evaluate $f$. This problem can be framed as a MDP 

\paragraph{Contextual multi-armed bandits}

\section{Gaussian processes as surrogate models in non-Euclidian manifolds}

% \begin{enumerate}
%     \item Low dimensions
%     \item Prior knowledge
%     \item Limited, noisy and very expensive data
%     \item Non-Euclidian spaces: graphs, meshes, and closed manifolds (e.g. circle).
% \end{enumerate}

Stationary kernels are ubiquitous in Gaussian processes when the input space is Euclidean. Their popularity is due to their general useability and the ease of understanding which prior information they encode. Recently, the extensions of stationary kernels to 


manifolds 
Descrete cases: undirected graph and meshes

Define Matern kernels:
\begin{equation}
    k(x, x) = \sum_i S(\sqrt{\lambda_i}) \phi_i(x) \phi_i(x')
\end{equation}

We want to place a \emph{surrogate model} between the expensive function $f$ and the algorithm. We model $\tilde{f}$ by a Gaussian process
\begin{equation}
    \tilde{f} \sim \GP
\end{equation}

\subsection{Research Questions}


\section{Applications}

\begin{enumerate}
    \item Bayesian search: airplane crash -> gravitational waves
\end{enumerate}


% Basically settings where DNNs are never going to be competitive with GPs - low-dim, very data-efficient, high-cost - not even if someone figures out how to do DNN uncertainty right, due to GP regret guarantees (under reasonable assumptions) matching the best possible regret achievable by any model/decision system.

\paragraph{Related areas}
\begin{enumerate}
    \item Probabilistic numerics [Tubingen Manifesto, Osborne and Henning]. They are less interested in closing the loop and making decisions atop of the models. They usually plot the error bars on the estimator as their final result.
    \item Bayesian optimisation methods. Special case.
\end{enumerate}



%%% OLD:

% Through this line of work, I believe that we have showed that (deep) Gaussian processes are an interesting non-parametric alternative to Bayesian neural networks (BNNs). Our work differs from the conventional BNN literature in that we attempt to scale well-understood fully-Bayesian models (i.e. GPs) to big data settings, rather than the converse: starting from complex parametric models and trying to approximate Bayesian inference in them. The former strategy allows to gradually build up complexity into the models while maintaining their favourable properties, such as a marginal likelihood objective and good uncertainty quantifications.

% In what comes next, I want to separate the different regimes in which neural networks and Gaussian processes operate and thrive. For example, NNs can handle---and in practice require---very large datasets, whereas Gaussian process models are more comfortable in the small data regime. Neural networks, in the presence of large datasets, are extremely good at learning complex latent representations, as evidenced by the latest models in natural language processing and computer vision. Non-parametric Gaussian processes, on the contrary, work best on limited and noisy datasets. Datasets where each datapoint can be very expensive in terms of cost or time to obtain. I believe that this is a setting---in the era of deep learning---that has been under studied and valued, yet of high importance for many scientific or commercial applications.

% Many real-world problems can be described as inferring properties of an expensive black-box function $f: \mathcal{X} \rightarrow \mathcal{Y}$, subject to a computational budget of $T$ function evaluations. Typical examples are (global) optimisation, finding a level set (i.e. the set of points in $X \subset \mathcal{X}$ for which $f(x) > C,\forall x \in X$), or finding the shortest path between two nodes in a graph. In the graph example, the black-box function $f$ would return the cost of traversing an edge and query the cost of an edge would be very expensive. Naively applying Dijkstra would require the evaluation of $f$ at every edge and thus potentially grossly exceeding the given budget of $T$ evaluations.


% \begin{enumerate}
%     \item Black Box Functions $f: \mathcal{X} \rightarrow \mathcal{Y}$
%     \item We want to estimate a computable property $\mathcal{O}_\mathcal{A}(f)$
%     \item $\mathcal{A}$ is an algorithm $\mathcal{O}_\mathcal{A}(f) = \mathcal{A}(f)$
%     \item Evaluating $f$ is \emph{very} expensive (we can only evaluate it a limited amount of times)
% \end{enumerate}

% \paragraph{Examples}
% \begin{enumerate}
%     \item Optimisation: $\mathcal{A}(f) = \argmax_{x\in\mathcal{X}} f(x)$, which implies $\mathcal{O}_\mathcal{A}(f) = x^*$.
%     \item Sensor Placement (Active Learning): $\mathcal{O}_\mathcal{A}(f) = \argmax_{X \subset \mathcal{X}, |X| = T} \textrm{MI}(f, f(X))$.
%     \item Level sets: $\mathcal{O}_\mathcal{A}(f) = \{X \subset \mathcal{X}: f(x) > C, \forall x \in X\}$.
%     \item Shortest path: $\mathcal{O}_\mathcal{A}(f) = $ shortest path between two nodes in a graph.
% \end{enumerate}

% \paragraph{Real-world problems}
% \begin{itemize}
%     \item[Graphs] Social networks. Search for cliques or shortest paths.
%     \item[Meshes] Aerospace and civil engineering problems. ``General'' sensor placement.
%     \item[Manifold] Sphere. Interesting problem in astrophysics: when a gravitational wave detection is made there's usually a very large uncertainty of its origin so optical telescopes have to sweep the sky looking for the source.
% \end{itemize}

% \paragraph{Objectives}
% \begin{enumerate}
%     \item Theory and analysis
%     \item Show the excellence of Gaussian processes in this regime
%     \item Benchmarks for future methods
% \end{enumerate}